### 論文リンク
https://arxiv.org/pdf/2401.00368.pdf
### 著者/所属機関
Microsoft Corporation
### 投稿年
2024
## 概要：
gpt-4でタスクごとに適したデータセットを生成して、InstructORと同じような手法で学習させるお話
## 研究背景
今までの埋め込みモデルはラベリングされたデータセットを必要とし、それに特化させるファインチューニングを行ってきた。問題点は２つ。ラベリングされたデータセットが必要な点。汎用性があまり高くない点である。
## 提案手法
・合成データを用いた学習
ex)retrival
まず、GPT-4に対して、検索タスクの候補をブレインストーミングするように促し、次に、各タスクに対して（クエリ、ポジティブ、ハードネガティヴ）トリプレットを生成する。
・関連するクエリとドキュメントのペア（q+, d+）が与えられたら、まず元のクエリq+に以下の命令テンプレートを適用し、新しいクエリq+を生成する：
・q’+ = Instruct: {task_definition} \n Query: {q+}
・クエリと文書の末尾に[EOS]トークンを付加し、次にそれらをLLMに送り込み、(hq’+ ,hd+)を得る
・InfoNCE損失関数を使用（モデルは、意味的に類似したテキスト間の距離を埋め込み空間上で小さくし、異なるテキスト間の距離を大きくする能力を獲得する）
## 実験
MTEBを用いた実験
Clustering, Sum以外でSOTA
## 感想
InstructORとデコーダ系のLLMを組み合わせたようなお話。PromptEOLがうまくいっているので直感的にもうまくいきそうな話。
塚越さんコメント：指示埋め込みした時とそうじゃない時の埋め込みの違いとか面白いかも
## 参考
