### 論文リンク
https://arxiv.org/pdf/2308.03281.pdf
### 著者/所属機関
Zehan Li1, Xin Zhang1, Yanzhao Zhang1, Dingkun Long1, Pengjun Xie1, Meishan Zhang 1Alibaba Group
### 投稿年
2023
## 概要：
教師なし対照学習をしてから教師あり対照学習を行うことで性能が上がる
## 研究背景
汎用的な文埋め込みはいまだに性能があまり高くない。
## 提案手法
教師なし対照学習をしてから教師あり対照学習を行うことで性能が上がる
## 実験
MTEBを用いた実験
## 感想

## 参考


### 論文リンク
https://arxiv.org/pdf/2305.01918.pdf
### 著者/所属機関
 Qinyuan Cheng, Xiaogui Yang, Tianxiang Sun, Linyang Li, Xipeng Qiu
### タイトル
Improving Contrastive Learning of Sentence Embeddings from AI Feedback
### 投稿年
2023
## 概要：
AIフィードバックを利用して対照的学習を改善するCLAIFの方法と、人間のフィードバックとAIフィードバックを組み合わせたCLHAIFの方法を提案。
両方の手法で、文埋め込みの学習において有意な改善をもたらした
## 研究背景
事前学習言語モデルから直接生成された文埋め込みは、セマンティックテキスト類似度タスクでのパフォーマンスが低いという問題があります。
この問題を解決するため、事前学習モデルをさらに改善する方法を見つけることが、自然言語処理において重要かつ基本的な課題となっています。
## 提案手法
文の一部をマスクさせて少し異なる文を生成させて、生成した文と生成元の文の類似度をgptに計算させることで作ったデータセットを用いて学習させる。
gptを人手のラベリングに近づけるようにMSEで学習させている
類似度が近いものを近づけ、遠いものを遠ざけるように学習。
## 実験
STSとSentEvalで評価。結果としてNLIデータセットよりも性能の高い文埋め込みモデルを生成できている
## 感想
Dinoはマスクではなく、全く異なる文を生成させ、1,0.5,0で考えていた
gptを学習させているのが、強い要因のように感じる
## 参考

### 論文リンク
https://arxiv.org/pdf/2309.12871.pdf
### 著者/所属機関
Xianming Li, Jing Li ∗
Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR
### タイトル
ANGLE-OPTIMIZED TEXT EMBEDDINGS
### 投稿年
2023
## 概要：
既存のテキスト埋め込みモデルが直面する共通の課題として、勾配が消失するという問題がある。
これは、最適化目的におけるコサイン関数に依存していることが主な原因であり、コサイン関数は飽和帯を持つ。
この問題に対処するため、本稿ではAnglEと呼ばれる新しい角度最適化テキスト埋め込みモデルを提案する。
AnglEの核となるアイデアは、複雑な空間における角度最適化を導入することである。
この新しいアプローチは、勾配を阻害し最適化プロセスを妨げるコサイン関数の飽和領域の悪影響を効果的に緩和する
## 研究背景
コサイン類似度では類似度が高いと、ベクトル間の微小な角度の変化が類似度スコアにほとんど影響を与えなくなるため、区別が困難になる。
## 提案手法
角度を最適化することで、余弦関数の飽和領域が学習プロセスに与える悪影響を緩和する。
具体的には、まずテキスト埋め込みを複素空間上で実部と虚部に分割する。
そして、複素数空間における分割規則に従って、2つのテキスト埋め込み間の角度差を計算する。
正規化後、角度差は最適化されるべき目的となる。
## 実験
STSで評価。SOTAを達成
## 感想
新しい学習手法で少し難しいが概ね理解できた。
## 参考
