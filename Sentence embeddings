### 論文リンク
https://arxiv.org/pdf/2308.03281.pdf
### 著者/所属機関
Zehan Li1, Xin Zhang1, Yanzhao Zhang1, Dingkun Long1, Pengjun Xie1, Meishan Zhang 1Alibaba Group
### 投稿年
2023
## 概要：
教師なし対照学習をしてから教師あり対照学習を行うことで性能が上がる
## 研究背景
汎用的な文埋め込みはいまだに性能があまり高くない。
## 提案手法
教師なし対照学習をしてから教師あり対照学習を行うことで性能が上がる
## 実験
MTEBを用いた実験
## 感想

## 参考

### 論文リンク
https://arxiv.org/pdf/2305.01918.pdf
### 著者/所属機関
 Qinyuan Cheng, Xiaogui Yang, Tianxiang Sun, Linyang Li, Xipeng Qiu
### タイトル
Improving Contrastive Learning of Sentence Embeddings from AI Feedback
### 投稿年
2023
## 概要：
AIフィードバックを利用して対照的学習を改善するCLAIFの方法と、人間のフィードバックとAIフィードバックを組み合わせたCLHAIFの方法を提案。
両方の手法で、文埋め込みの学習において有意な改善をもたらした
## 研究背景
事前学習言語モデルから直接生成された文埋め込みは、セマンティックテキスト類似度タスクでのパフォーマンスが低いという問題があります。
この問題を解決するため、事前学習モデルをさらに改善する方法を見つけることが、自然言語処理において重要かつ基本的な課題となっています。
## 提案手法
文の一部をマスクさせて少し異なる文を生成させて、生成した文と生成元の文の類似度をgptに計算させることで作ったデータセットを用いて学習させる。
gptを人手のラベリングに近づけるようにMSEで学習させている
類似度が近いものを近づけ、遠いものを遠ざけるように学習。
## 実験
STSとSentEvalで評価。結果としてNLIデータセットよりも性能の高い文埋め込みモデルを生成できている
## 感想
Dinoはマスクではなく、全く異なる文を生成させ、1,0.5,0で考えていた
gptを学習させているのが、強い要因のように感じる
## 参考
